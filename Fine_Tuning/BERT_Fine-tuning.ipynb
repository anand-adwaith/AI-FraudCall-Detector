{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12269442,"sourceType":"datasetVersion","datasetId":7731664}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import requests\nresponse = requests.get(\"https://huggingface.co\")\nprint(response.status_code)  # Should print 200","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T12:55:07.784297Z","iopub.execute_input":"2025-06-24T12:55:07.785135Z","iopub.status.idle":"2025-06-24T12:55:07.915932Z","shell.execute_reply.started":"2025-06-24T12:55:07.785105Z","shell.execute_reply":"2025-06-24T12:55:07.915141Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom datasets import Dataset\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSequenceClassification,\n    TrainingArguments,\n    Trainer\n)\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nimport torch\n\n# 1. Verify GPU availability\nif not torch.cuda.is_available():\n    raise RuntimeError(\"GPU not available. Please enable GPU in Kaggle settings.\")\nprint(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n\n# 2. Load and clean dataset\ntry:\n    df = pd.read_csv(\"/kaggle/input/bert-scam/SyntheticDataSet_Call_Text_5.csv\")  # Adjust path for Kaggle\nexcept FileNotFoundError:\n    raise FileNotFoundError(\"Dataset file 'SyntheticDataSet.txt' not found in /kaggle/input/\")\n\ndf = df[['text', 'label']].rename(columns={'text': 'text', 'label': 'label'})\ndf = df.dropna(subset=['text', 'label'])\n# Normalize labels and cast to integers\ndf['label'] = df['label'].str.lower()\ndf['label'] = df['label'].map({'fraud': 1, 'normal': 0})\ndf['label'] = df['label'].astype(int)\nprint(f\"Label dtype: {df['label'].dtype}\")\nprint(f\"Unique labels: {df['label'].unique()}\")\nassert df['label'].isnull().sum() == 0, \"Label mapping failed.\"\nassert df['label'].isin([0, 1]).all(), \"Labels contain unexpected values.\"\nprint(f\"Label distribution: {df['label'].value_counts()}\")\nprint(f\"Text length stats: {df['text'].str.len().describe()}\")\nprint(f\"Duplicates: {df.duplicated().sum()}\")\n\n# 3. Train-test split\ntrain_df, test_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)\ntrain_ds = Dataset.from_pandas(train_df.reset_index(drop=True))\ntest_ds = Dataset.from_pandas(test_df.reset_index(drop=True))\n\n# 4. Tokenization\nmodel_checkpoint = \"bert-base-multilingual-cased\"\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n\ndef tokenize_function(example):\n    return tokenizer(example['text'], truncation=True, padding=\"max_length\", max_length=128)\n\ntrain_ds = train_ds.map(tokenize_function, batched=True)\ntest_ds = test_ds.map(tokenize_function, batched=True)\ntrain_ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\ntest_ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n\n# 5. Load model\nmodel = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=2)\nmodel.to(\"cuda\")  # Move model to GPU\n\n# 6. Define metrics\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    preds = logits.argmax(axis=1)\n    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n    acc = accuracy_score(labels, preds)\n    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}\n\n# 7. Define training args\ntraining_args = TrainingArguments(\n    output_dir=\"/kaggle/working/results\",  # Kaggle output directory\n    eval_strategy=\"epoch\",\n    per_device_train_batch_size=32,  # Increased for GPU\n    per_device_eval_batch_size=64,   # Increased for GPU\n    num_train_epochs=4,\n    weight_decay=0.01,\n    logging_dir=\"/kaggle/working/logs\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    metric_for_best_model=\"f1\",\n    report_to=\"none\",\n    logging_strategy=\"epoch\",\n    fp16=True  # Enable mixed precision for GPU\n)\n\n# 8. Trainer setup\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_ds,\n    eval_dataset=test_ds,\n    processing_class=tokenizer,\n    compute_metrics=compute_metrics\n)\n\n# 9. Train\ntrainer.train()\n\n# 10. Save model\nmodel_path = \"/kaggle/working/bert-spam-model2\"\ntrainer.save_model(model_path)\ntokenizer.save_pretrained(model_path)\n\n# 11. Optional: Save model to Kaggle output for download\nimport shutil\nshutil.make_archive(\"/kaggle/working/bert-spam-model2\", 'zip', model_path)\nprint(f\"Model saved and zipped at /kaggle/working/bert-spam-model2.zip\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T12:55:09.946337Z","iopub.execute_input":"2025-06-24T12:55:09.946971Z","iopub.status.idle":"2025-06-24T13:03:58.553114Z","shell.execute_reply.started":"2025-06-24T12:55:09.946945Z","shell.execute_reply":"2025-06-24T13:03:58.552218Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'bert-spam-model2.zip')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T13:05:31.478207Z","iopub.execute_input":"2025-06-24T13:05:31.478920Z","iopub.status.idle":"2025-06-24T13:05:31.484019Z","shell.execute_reply.started":"2025-06-24T13:05:31.478891Z","shell.execute_reply":"2025-06-24T13:05:31.483308Z"}},"outputs":[],"execution_count":null}]}